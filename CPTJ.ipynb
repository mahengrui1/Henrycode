{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python-中文分词词频统计\n",
    "zcmlimi\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「zcmlimi」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/zcmlimi/java/article/details/90671005\n",
    "\n",
    "20200520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    " \n",
    "#os.chdir(r'C:\\Users\\zhuchaoming\\Desktop\\任务\\其他文件\\分词')\n",
    "txt = open(\"斗破苍穹.txt\", encoding=\"UTF-8\").read()\n",
    "\n",
    "cixingset=1#1 use jieba cixing, 0 don't use it\n",
    "allL=[5,6,7,8,9,10]#[0] is using jieba 分词, [5,6,7,8,9,10] etc is 全分词\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanfenciall(txt,allL):\n",
    "#    allL=range(10) input a str and out ut a list full of continous word in list allL length.\n",
    "#don't use it for long text since the n is about n**2\n",
    "    allThe=[]\n",
    "    for L in allL:\n",
    "        if L>1:\n",
    "            allThe=allThe+[txt[a:a+L] for a in range(len(txt)-L)]#+sorted(set(The),key=The.index)\n",
    "    return allThe\n",
    "\n",
    "def quanfenci(txt,L):\n",
    "#    L=10 input a str and out ut a list full of continous word in list allL length.\n",
    "    allThe=[]\n",
    "    if L>1:\n",
    "        allThe=[txt[a:a+L] for a in range(len(txt)-L)]#+sorted(set(The),key=The.index)\n",
    "    return allThe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting jieba cixing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Temp\\jieba.cache\n",
      "Loading model cost 2.079 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting L=5\n",
      "starting L=6\n",
      "starting L=7\n",
      "starting L=8\n",
      "starting L=9\n",
      "starting L=10\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n",
      "dealing jieba cixing\n",
      "dealing Number\n",
      "sorting\n",
      "merging\n"
     ]
    }
   ],
   "source": [
    "#词xing统计\n",
    "#stopwords = [line.strip() for line in open(\"stopword.txt\",encoding=\"gb18030\").readlines()]\n",
    "cixing=[]\n",
    "if cixingset:\n",
    "    print('starting jieba cixing')\n",
    "    cixing = pseg.lcut(txt)#need time\n",
    "\n",
    "\n",
    "if allL==[0]:\n",
    "    print('starting jieba cut')\n",
    "    count  = jieba.lcut_for_search(txt)#need time\n",
    "else:\n",
    "    for L in allL:\n",
    "        print('starting L='+str(L))\n",
    "        count = quanfenci(txt,L)\n",
    "        \n",
    "count=[a for a in count if len(a)>1]#only 2 char or more\n",
    "allitems={}\n",
    "for L in allL:\n",
    "    if L==0:\n",
    "        print('starting L='+str(L))\n",
    "        print('starting L='+str(L))\n",
    "\n",
    "    word_count = {}\n",
    "    word_flag = {}\n",
    "    all=[]\n",
    "\n",
    "#词性统计\n",
    "    print('dealing jieba cixing')\n",
    "    for w in cixing:\n",
    "        word_flag[w.word] = w.flag\n",
    "\n",
    "    #词频统计\n",
    "    print('dealing Number')\n",
    "    for word in count:\n",
    "        word_count[word] = word_count.get(word, 0) + 1#need time\n",
    "\n",
    "    #delete less than 5\n",
    "    for key in list(word_count.keys()):\n",
    "        if word_count.get(key)<6:\n",
    "            del word_count[key]\n",
    "    print('sorting')\n",
    "    items = list(word_count.items())\n",
    "\n",
    "    with codecs.open(filename='word_count_L'+str(L)+'.csv', mode='w', encoding='UTF-8')as f:\n",
    "        write = csv.writer(f, dialect='excel')\n",
    "        write.writerow(['L='+str(L),'',''])\n",
    "        write.writerow([\"word\",\"count\",\"flag\"])\n",
    "\n",
    "\n",
    "        #按词频排序\n",
    "        items.sort(key=lambda x: x[1], reverse=True)\n",
    "        #查询词频字典里关键字的词性\n",
    "        print('merging')\n",
    "        for i in range(len(items)):\n",
    "            word=[]\n",
    "            word.append(items[i][0])\n",
    "            word.append(items[i][1])\n",
    "            # 若词频字典里，该关键字有分辨出词性，则记录，否则为空\n",
    "            if items[i][0] in word_flag.keys():\n",
    "                word.append(word_flag[items[i][0]])\n",
    "            else:\n",
    "                word.append(\"\")\n",
    "            all.append(word)\n",
    "\n",
    "\n",
    "        for res in all:\n",
    "            write.writerow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on pair in module jieba.posseg object:\n",
      "\n",
      "class pair(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, word, flag)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |  \n",
      " |  encode(self, arg)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cixing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-ce48075e8c16>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-ce48075e8c16>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    jupyter notebook --generate-config\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter notebook --generate-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'a', 2]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'a', 2, 'a', 'b', 'a', 2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(b),key=b.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
